# 생성 모델 기반 적대적 공격의 전이성 향상을 위한 구분 모델의 특성 지도 마스킹 방법

### 손민지 등 - 2022


1. 서론

적대적 예제와, 적대적 공격에 대한 간략한 설명

화이트 박스와 블랙박스 공격에 대한 간략한 설명

블랙 박스 공격이 화이트 박스 공격에 비해 현실적 ⇒ 전이성 이용

적대적 예제 생성 방법

- 반복적인 방법 (iterative method)

이미지마다 손실함수 증가 방향으로 최적화 진행해 교란 잡음 생성 후 입력 이미지에 더해 적대적 예제 생성

- 생성 모델 기반 방법 (generative method)

손실함수 증가 방향으로 생성모델 학습 후 이미지 입력하여 적대적 예제 출력

빠르게 적대적 예제 생성 ⇒ 빠른 공격이 가능하다는 점

논문에서는 전이성 향상 위해 부분 마스킹한 특성 지도 사용하여 생성모델 학습

학습 데이터에 대한 모델에 특정 정보 영향 줄이면서 입력 이미지에 과적합되는 것을 방지하여 전이성 높임

1. 본론
- 생성 모델 기반 적대적 예제 생성

교란 잡음 크기 제한되지 않은 적대적 예제 G(x)를 출력해, 적대적 예제와 원본 이미지 사이의 거리가 최대 잡음 크기 입실론 이내의 값을 가지도록 제한하여 적대적 예제 생성

- 특성 지도 마스킹 이용해 생성모델 학습

학습 후 학습 데이터와 같은 분포를 가지는 대부분의 데이터에 대해 적대적으로 작용하는 적대적 예제 생성

1. 이미지 분류 모델에 원본 이미지와 생성된 적대적 예제를 넣어 특성지도 추출
2. 특성 공간에서 두 특성 지도 거리가 멀어지도록 학습하기 위해 특성지도 분리 손실 함수 사용

![image](https://user-images.githubusercontent.com/108413432/229329166-0f3a5f62-0108-4175-afbb-52fbd15d75aa.png)

1. 특성 지도와 동일한 크기를 가지고 일정 비율 0 or 1 값 지닌 임의의 마스크 Mi를 n개 생성 후, 특성 지도에 원소별 곱 하여 일부의 값을 가진 특성 지도 n개 생성
2. 생성된 특성지도와 원본의 특성 지도 사이의 L2 거리 평균으로 과적합되는 것을 방지하기 위해 마스크 씌운 특성 지도 손실 함수 사용

![image](https://user-images.githubusercontent.com/108413432/229329175-84d02599-cb62-4b71-b327-4bcb586636df.png)

1. 두 손실 함수를 더한 손실함수가 증가하는 방향으로 max G를 학습 ⇒ 높은 전이성의 적대적 예제 생성

1. 실험

ImageNet 데이터셋 활용

선생 연구와 같이 학습 검증 데이터 셋 이미지 사용해 전이성 측정

6개의 신경망 사용 - SqueezeNet, ResNet-152, VGG-16, Inception-v3, Densenet 121, Mnasnet

4개의 모델을 구분자로 사용해 생성 모델 학습

특성 지도 분리(Feature Seperation)방법의 속임률과 오류 항상 정도와 값을 비교

1. 결론

과적합 방지와 생성 모델 학습 위해 새로운 손실 함수 제안

특성 지도 일부를 마스킹 하는 방법 이용해 생성 모델 학습하면 전이성 효과적 향상

클래스 활성 지도(Class Activation Map) 방법으로 특성 지도에서 중요 부분 이용해 생성 모델 학습 시키니는 방법 통해 전이성 효율적 향상 시키도록 할 예정
