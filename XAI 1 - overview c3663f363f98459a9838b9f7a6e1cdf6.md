# XAI 1 - overview

### 1. Overview

[https://www.youtube.com/watch?v=Grc7egfZP84&t=503s](https://www.youtube.com/watch?v=Grc7egfZP84&t=503s)

[https://arxiv.org/abs/2006.11371](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbk1wdWthRUdzWDlOLWVvcTRZREdiU3RrV1M2Z3xBQ3Jtc0tsZG1xcW93U0o2VVp4MW1CczhqTE1NMWdlNUxMY2YzcEV6MFpONDRKdDRkYmNIT1BOeFRDczM4VUNyWmZ1MGw5YTBoTHZpTkRGTUpWcnFKMjg3QnRXY180Y2x1LWd5Wm54UEFSM2p2SnRnMGc2Tlh4aw&q=https%3A%2F%2Farxiv.org%2Fabs%2F2006.11371&v=Grc7egfZP84)

XAI : 인간의 explanation이 아닌 AI가 explanation을 도출하며, 사람이 AI의 동작과 최종결과를 이해하고 올바르게 해석할 수 있고, 결과물이 생성되는 과정을 설명 가능하도록 해주는 기술

Why? / Why not? / When? (실패 할 때) / How to fix? ⇒XAI

효과 - 투명성 (Trnasparency), 신용성 (Trust), Bias와 Fairness

### 종류

1. 분류 기준 : Scope (XAI가 어디에 focus를 하는지)
- Local - Individual data를 설명, 개개인에 대한 하나의 explanation map 생성
- Global - 모델 전체를 한 단위로 인식, group 에 대한 하나의 explanation map 생성

1. Local 방법론
    - Activation maximization : CNN의 각 labey 중요성 알기 위해 특정 hidden unit activation 최대화하는 input pattern 탐지 → input 별 feature importance를 찾기 위해
    - Saliency Map Visualization : 각 output class 해당하는 gradient를 픽셀별로 계산해 각 픽셀 중요성 (pixel importance) 도출
    
    ![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled.png)
    
    - LRP (Layer-wise Relevance BackPropagation) : output prediction을 back propagation 통해 분해해 input data의 각 feature의 relevance score 도출

b. Global 방법론

- Class Model Visualization : Activation maximization 을 global explanation 으로 확장

![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%201.png)

- CAVs (Concept Activation Vectors) : Postive (사람이 구분하는 컨셉)와 negative concept을 구분하는 방법 → binary classification
- TCAVs : testing with CAVs → directional derivatives 활용해 class prediction의 sensitivity 평가 방법론
- SpRAy (Spectral Relevance Analysis) : 군집화한 후 relevant 한 입력값 도출
    - LRP통해 relevance socre구하고, score 기반 입력값 군집화(Spectral Cluster) 방법 사용 → eigenvalue 간 차이 기반으로 가장 relevant한 cluster찾고 가장 중요한 클러스터를 결과값으로 도출
        
        ![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%202.png)
        

1. 분류기준 : Methodology (알고리즘이 backpropagation 을 base로 하는지, Perturbation 을 base로 하는지)
- BackPropagtion (Gradient) based : backpropagated된 gradient통해 relevance를 파악하거나 Saliency Map을 도출해내어 Pixel Importance 파악
- Perturbation based : 입력 데이터의 feature 상 변화에 의존적이므로 변화에 따른 input과 output의 relevance 파악

1. Gradient based
    - Saliency Map - CNN prediction 해석하는데 가장 자주 쓰임
        - 이미지 안에 어떤 부분이 classification에 relevant 한지 highlight 함
        
        ![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%203.png)
        
    - GradCAM (Gradient Class Activation Mapping) - 마지막 완전연결층 대신 GAP (Global Average Pooling) 사용해 위치 정보를 보존하여 마지막 Conv layer에서 class 수만큼의 채널을 갖게한 후 채널 기준으로 평균 구해 각 class 대응 값찾아 가장 큰 값을 class로 예측함
        - weight들을 각 feature map에 곱하여 합치면 무엇을 보고 이 feature map이 class로 분류했는지 알수 있도록
    
    ![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%204.png)
    
    - Salient Relevance Maps : Saliency Map과 유사하지만 Context aware한 정보까지 포함함
        - SpRAy와 동일하게 LRP 활용하지만 각 입력에 대해 LRP relevance score를 활용하는게 다름
    
    ![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%205.png)
    
    - Attribution Maps
        - Integrated Gradient (IG), Expected Gradients (EG) ⇒ 도메인 데이터를 곱해줌

b. Perturbation based

- DeConvolution nets for Convolution Visualizations- CNN 진행방향과 반대 되는 방향으로 진행
    - input 이미지상 조금 변화도 Reconstruction 과정을 거치면서 어떻게 변했는 지 알 수 있음

![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%206.png)

- RISE(Randomized Input Sampling for Explanation)
    - 입력 이미지에 랜덤한 mask 곱한 후 black box 함수인 f를 거쳐 분류에 대한 confidence score를 리턴 시킴
    - mask와 confidence socre들을 weighted sum해 Saliency map 리텀 시킴
    - 높은 출력 갖게 만든 랜덤 mask 특정 노출에 일관성을 보여주어 적절한 설명 가능 (랜덤하기에 수행할 때마다 결과 달라짐)

![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%207.png)

1. 분류 기준 : Usage (다른 구조에 적용할 수 있는지)
    - Intrinsic - 다른 구조에 적용 못함
    - Post-Hoc - 모델 구조에 구애 받지 않음 (이미 훈련된 NN에 적용 가능)
    

### 평가

1. System Causability Scale (SCS) - XAI에서 중요한 10개 선정해 긍/부정 점수

![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%208.png)

1. Benchmarking Attribution Methods (BAM) - Feature attribution 과 relative importance 가 어느정도 정확한지 측정 위함

1. Faithfulness and Monotonicity 
    - Faithfulness : 특징 중요도와 각 피처의 performance effect 간 상관관계 계산
    - Monotonicity : 특징 중요도에 따라 모델에 피처를 점진적 더해 나가며 각 데이터 피처의 성능 기여도 측정

1. Human-grounded Evaluation Benchmark - 사람 평가를 벤치마크 삼아 설명 모델 평가, 최대한 human bias 제거하고자 함

### Case Study of XAI

![Untitled](XAI%201%20-%20overview%20c3663f363f98459a9838b9f7a6e1cdf6/Untitled%209.png)

### Limitation

1. 사람이 XAI의 xplanation maps 추론 힘듦
2. XAI 알고리즘에 대한 정량적 평가 어려